{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Run Active Learning w/o unsupervised bootstrapping\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import md5, sha\n",
    "    run_boot_al()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noisy_activelearning import *\n",
    "from datautils import*\n",
    "from bootstrapping import*\n",
    "from bootstrapping_unsupervised import*\n",
    "from datetime import date\n",
    "from learning import *\n",
    "from libact_datasetext import *\n",
    "\n",
    "#set parameters\n",
    "dataPathmain = \"../datasets/wdc_product\"\n",
    "query_strategy = 'default_committee'\n",
    "model_type = 'rf'\n",
    "dataset = 'headphones_headphones_catalog'\n",
    "domain = 'wdc_product'\n",
    "boot_size = 0\n",
    "max_queries = 100\n",
    "al_runs = 5\n",
    "bootstrap_method = 'attrelbow_density' \n",
    "no_boot = False\n",
    "boot = True\n",
    "\n",
    "#prepare result tables\n",
    "column_names = [\"method\", \"1st iter.\", \"50th iter.\"]\n",
    "for i in range(0, max_queries/100):\n",
    "    column_names.append(\"%dth iter.\" %((i+1)*100))\n",
    "\n",
    "iteration_results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "all_column_names = [\"method\"]\n",
    "for i in range(0, max_queries):\n",
    "    all_column_names.append(\"%dth iter.\" %(i))\n",
    "full_results = pd.DataFrame(columns=all_column_names)\n",
    "\n",
    "def run_boot_al():\n",
    "                   \n",
    "    #get data\n",
    "    featureFile_pool = dataPathmain+'/features_'+dataset+'_train'\n",
    "    featureFile_validation = dataPathmain+'/features_'+dataset+'_test'\n",
    "\n",
    "    trainingData = getLabelledDataFromFile(featureFile_pool, rescale=True)\n",
    "    validationData = getLabelledDataFromFile(featureFile_validation, rescale=True)\n",
    "\n",
    "    X = trainingData['feature_values']\n",
    "    y = trainingData['labels']\n",
    "    ids = trainingData['ids']\n",
    "\n",
    "    #NO BOOTSTRAPPING\n",
    "    if (no_boot):\n",
    "        bootstrap = BootstrappingUnsupervised(sample_size=0, data=X, labels=y, ids=ids, bootstrap_method='bowtopbottom', domain=domain)\n",
    "        bootstrapping_sample = bootstrap.sample\n",
    "\n",
    "        al= dict()\n",
    "        al['pool_data']= X\n",
    "        al['pool_labels']= y\n",
    "        al['ids'] = ids\n",
    "\n",
    "        al['validation_data']= validationData['feature_values']\n",
    "        al['validation_labels']= validationData['labels']\n",
    "\n",
    "        al['bootstrapping_data']= bootstrapping_sample['data']\n",
    "        al['bootstrapping_labels']= bootstrapping_sample['labels']\n",
    "        al['bootstrapping_indices']=bootstrapping_sample['indices']\n",
    "        al['bootstrapping_scores'] = bootstrapping_sample['scores']\n",
    "\n",
    "        display(Markdown(\"<span style='color:blue;font-size:160%'><b> Active Learning with default_committee Sampling, no Bootstrapping</b></span>\" ))\n",
    "        f1_test = active_learning(al, query_strategy, max_queries, al_runs, model_type)\n",
    "        addtoresultstable(\"noboot\", f1_test, iteration_results)\n",
    "\n",
    "        display(Markdown(\"<span style='color:blue;font-size:160%'><b> Active Learning with default_committee Sampling, no Bootstrapping and warm start</b></span>\" ))\n",
    "        f1_test = active_learning(al, query_strategy, max_queries, al_runs, model_type, warm_start=True)\n",
    "        addtoresultstable(\"noboot_warm_start\", f1_test, iteration_results)\n",
    "\n",
    "   \n",
    "    #UNSUPERVISED BOOTSTRAPPING\n",
    "    if (boot):\n",
    "        bootstrap = BootstrappingUnsupervised(data=X, labels=y, ids=ids, bootstrap_method=bootstrap_method, domain=domain)\n",
    "        bootstrapping_sample = bootstrap.sample\n",
    "        boot_thres_index = bootstrap.threshold_index\n",
    "        al= dict()\n",
    "        al['pool_data']= X\n",
    "        al['pool_labels']= y\n",
    "        al['ids'] = ids\n",
    "\n",
    "        al['validation_data']= validationData['feature_values']\n",
    "        al['validation_labels']= validationData['labels']\n",
    "\n",
    "        al['bootstrapping_data']= bootstrapping_sample['data']\n",
    "        al['bootstrapping_labels']= bootstrapping_sample['labels']\n",
    "        al['bootstrapping_indices']=bootstrapping_sample['indices']\n",
    "        al['bootstrapping_scores'] = bootstrapping_sample['scores']\n",
    "        al['bootstrapping_threshold'] = bootstrap.threshold\n",
    "\n",
    "\n",
    "        display(Markdown(\"<span style='color:blue;font-size:160%'><b> Active Learning with \"+query_strategy+\" Sampling and Noisy but Interesting Bootstrapping score_based Reweight Warm Start</b></span>\"))\n",
    "\n",
    "        f1_test_noisy_reweight, pool_correctness = noisy_active_learning(al, query_strategy, max_queries, al_runs,\n",
    "                                                          model_type, setting=None, reweight='score_based', warm_start=True)\n",
    "\n",
    "        addtoresultstable(\"noisy_warm_\"+query_strategy, f1_test_noisy_reweight, iteration_results)\n",
    "        addtoresultstable(\"unsupervised_correctness\", pool_correctness, iteration_results)\n",
    "\n",
    "    display(iteration_results)\n",
    "    \n",
    "def addtoresultstable(method_name, results, resultstable):\n",
    "    index = resultstable.shape[0]\n",
    "    mean_f1 = np.mean(results, axis=0)\n",
    "    std_f1= np.std(results, axis=0)\n",
    "    \n",
    "    \n",
    "    f1_line = [method_name] + [\"%.3f\" %mean_f1[0]] + [\"%.3f\" %mean_f1[49]]\n",
    "    std_line = [\"st. deviaton\"] + [\"%.3f\" %std_f1[0]] + [\"%.3f\" %std_f1[49]]\n",
    "    \n",
    "    for i in range(0, max_queries/100):\n",
    "        position = (i+1)*100 - 1\n",
    "        f1_line += [\"%.3f\" %mean_f1[position]]\n",
    "        std_line += [\"%.3f\" %std_f1[position]]\n",
    "    resultstable.loc[index] = f1_line\n",
    "    resultstable.loc[index+1] = std_line\n",
    "    \n",
    "    f1_line = [method_name]\n",
    "    std_line = [\"st. deviaton\"]\n",
    "    for i in range(0,max_queries):\n",
    "        f1_line += [\"%.3f\" %mean_f1[i]]\n",
    "        std_line += [\"%.3f\" %std_f1[i]]\n",
    "    index_full = full_results.shape[0]\n",
    "    full_results.loc[index_full] = f1_line\n",
    "    full_results.loc[index_full+1] = std_line\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

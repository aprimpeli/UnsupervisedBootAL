{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/aprimpel/python_env/activelearning_env/local/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unsupervised Matching: DBPediaAuthors_VIAFDataAuthors'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats about pool data\n",
      "Rescale values\n",
      "Nan values in input labelled data:  0\n",
      "Replace all Nan values with -1\n",
      "Profiling Density\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'birthdate': '0.834',\n",
       " 'cosine': '1.000',\n",
       " 'deathdate': '0.508',\n",
       " 'gender': '0.976',\n",
       " 'label': '1.000',\n",
       " 'work': '0.363'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats about validation data\n",
      "Rescale values\n",
      "Nan values in input labelled data:  0\n",
      "Replace all Nan values with -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Training size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue;font-size:160%'><b> Get bootstrapped pairs using feature value pairwise similarity *all* weighted by the feature density (*0.5) and cosine with tfidf (*0.5). </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee of the curve is at index = 13007\n",
      "Knee value = 0.368146172796359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Define Elbow threshold: 0.368146 '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider everything above the threshold as positive and below as negative.\n",
      "Class distribution in sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 13007, 1: 2309}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method attrelbow_density gives 0.940541 prec, 0.819466 recall and 0.875839 f1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue;font-size:160%'><b> Get bootstrapped pairs using feature value pairwise similarity *all* weighted by the feature density (*0.5) and cosine with tfidf (*0.5). </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Define static threshold (0.5) and take positive and negative elements'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold defined with static method threshold (0.5): 0.500112\n",
      "Consider everything above the threshold as positive and below as negative.\n",
      "Class distribution in sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 14049, 1: 1267}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method attrstatic_density gives 1.000000 prec, 0.475667 recall and 0.644681 f1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue;font-size:160%'><b> Get bootstrapped pairs using feature value pairwise similarity *all* weighted by the feature density (*0.5) and cosine with tfidf (*0.5). </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find Otsu's threshold: |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% Complete\n",
      "Threshold defined with Otsu's method: 0.295017 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Define Otsu's threshold: 0.295017\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider everything above the threshold as positive and below as negative.\n",
      "Class distribution in sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 9263, 1: 6053}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method attrotsu_density gives 0.388259 prec, 0.913658 recall and 0.544944 f1\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue;font-size:160%'><b> Get bootstrapped pairs using feature value pairwise similarity *all* weighted by the feature density (*0.5) and cosine with tfidf (*0.5). </b></span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find Valley threshold: |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% Complete\n",
      "Threshold defined with valley threshold method: 0.395237 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Define Valley threshold: 0.395237'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider everything above the threshold as positive and below as negative.\n",
      "Class distribution in sample:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 13292, 1: 2024}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Training size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "15316"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Validation size:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method attrvalley_density gives 0.983806 prec, 0.762951 recall and 0.859416 f1\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "8 columns passed, passed data had 7 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-29671b9ab17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# run thresholding comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mthresholding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-297d10088f75>\u001b[0m in \u001b[0;36mthresholding\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mbootstrap_sample_correctness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_sample_f1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprecision_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecall_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Dataset'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'Bootstrap sample correctness'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bootstrap sample f1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Method'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Learn. Alg.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aprimpel/python_env/activelearning_env/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    433\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aprimpel/python_env/activelearning_env/local/lib/python2.7/site-packages/pandas/core/internals/construction.pyc\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m--> 404\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m    405\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[0;32m/work/aprimpel/python_env/activelearning_env/local/lib/python2.7/site-packages/pandas/core/internals/construction.pyc\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[0;32m--> 436\u001b[0;31m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/aprimpel/python_env/activelearning_env/local/lib/python2.7/site-packages/pandas/core/internals/construction.pyc\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    490\u001b[0m             raise AssertionError('{col:d} columns passed, passed data had '\n\u001b[1;32m    491\u001b[0m                                  '{con} columns'.format(col=len(columns),\n\u001b[0;32m--> 492\u001b[0;31m                                                         con=len(content)))\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# provide soft conversion of object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 8 columns passed, passed data had 7 columns"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from datautils import*\n",
    "from IPython.display import Markdown, display\n",
    "import numpy as np\n",
    "from preprocessing import*\n",
    "from learning import*\n",
    "from bootstrapping import*\n",
    "from bootstrapping_unsupervised import*\n",
    "from similarityutils import*\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# run thresholding comparison\n",
    "thresholding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start from here\n",
    "def thresholding():\n",
    "   \n",
    "    #set these parameters   \n",
    "    bootstrap_methods = ['attrelbow_density','attrstatic_density', 'attrotsu_density','attrvalley_density']\n",
    "    threshold_labels = ['elbow', 'static', 'otsu\\'s', 'valley']\n",
    "    threshold_colors = ['blue', 'green', 'orange', 'magenta']\n",
    "    threshold_text = [50, 100, 150, 200]\n",
    "    thresholds = []\n",
    "    model = 'rf'\n",
    "    dataPathmain = \"../datasets/author\"\n",
    "    domain = 'author'\n",
    "    datasets = [ 'DBPediaAuthors_VIAFDataAuthors']\n",
    "        \n",
    "      \n",
    "    for dataset in datasets:\n",
    "        model_ = []\n",
    "        method_ = []\n",
    "        precision_=[]\n",
    "        precision_sigma=[]\n",
    "        recall_=[]\n",
    "        recall_sigma=[]\n",
    "        f1_=[]\n",
    "        f1_sigma = []\n",
    "        bootstrap_sample_correctness = []\n",
    "        bootstrap_sample_f1 = []\n",
    "\n",
    "        dataset_=[]\n",
    "        \n",
    "        #get data and profiling information\n",
    "        display(\"Unsupervised Matching: %s\" %dataset)\n",
    "        \n",
    "        featureFile_train = dataPathmain+'/features_'+dataset+'_train'\n",
    "        featureFile_test = dataPathmain+'/features_'+dataset+'_test'\n",
    "        \n",
    "        print(\"Stats about pool data\")\n",
    "        trainingData = getLabelledDataFromFile(featureFile_train, rescale=True)\n",
    "        print(\"Profiling Density\")\n",
    "        prof_results = dict()\n",
    "        data_values = trainingData['feature_values']\n",
    "        tobedropped=[]\n",
    "        for c in data_values.columns:\n",
    "            empty_values = len(data_values[data_values[c] == -1])\n",
    "            per= float(empty_values)/float(len(data_values[c]))\n",
    "            density = 1-per\n",
    "           \n",
    "            #drop non-dense attributes for the wdc datasets\n",
    "            if 'wdc_product' in domain:\n",
    "                column_name = c\n",
    "            else: column_name = c.split(\"_\")[0]\n",
    "            if (density<0.1):tobedropped.append(c)\n",
    "            else: prof_results[column_name]= (\"%.3f\" %density)\n",
    "        \n",
    "        if 'wdc_product' in domain:\n",
    "            print (\"Columns to be dropped:\", len(tobedropped))\n",
    "            trainingData['feature_values'] = trainingData['feature_values'].drop(tobedropped, axis=1)\n",
    "        display(prof_results)\n",
    "        print(\"Stats about validation data\")\n",
    "        validationData = getLabelledDataFromFile(featureFile_test, rescale=True)\n",
    "        if 'wdc_product' in domain:\n",
    "            validationData['feature_values'] = validationData['feature_values'].drop(tobedropped, axis=1)\n",
    "\n",
    "        \n",
    "        X = trainingData['feature_values']\n",
    "        y = trainingData['labels']\n",
    "        ids  = trainingData['ids']\n",
    "        bootstrap_sample_correctness\n",
    "    \n",
    "        #get results for supervised matching\n",
    "        prec, recall, fscore, support = batchTraining(X,y,validationData['feature_values'],validationData['labels'],model, printResults = False,\n",
    "                                                           optimization=False)\n",
    "        precision_.append(\"%.3f\" %prec)\n",
    "        recall_.append(\"%.3f\" %recall)\n",
    "        f1_.append(\"%.3f\" %fscore)\n",
    "        model_.append(model)\n",
    "        \n",
    "        dataset_.append(dataset)\n",
    "        method_.append('Passive Supervised Learning')\n",
    "        bootstrap_sample_correctness.append(\"-\")\n",
    "        bootstrap_sample_f1.append(\"-\")\n",
    "        for m in bootstrap_methods:\n",
    "\n",
    "            bootstrap = BootstrappingUnsupervised(data=X, labels=y, ids=ids, bootstrap_method=m, domain=domain)\n",
    "            sorted_dataset = bootstrap.sorted_dataset\n",
    "            thresholds.append(bootstrap.threshold)\n",
    "\n",
    "            bootstrapping_sample = bootstrap.sample\n",
    "            bootstrap_sample_correctness.append(bootstrapping_sample['correctness'])\n",
    "            bootstrap_sample_f1.append(bootstrapping_sample['f1'])\n",
    "\n",
    "            prec, recall, fscore, support = batchTraining(bootstrapping_sample['data'],bootstrapping_sample['labels'],\n",
    "                                                          validationData['feature_values'],validationData['labels'],model, printResults = False, optimization=False,\n",
    "                                                          showMisclassifications = False, ids = ids)\n",
    "\n",
    "            print(\"Method %s gives %f prec, %f recall and %f f1 if noisy data are used to train a RF\" % (m, prec, recall, fscore))\n",
    "            \n",
    "            method_.append(m)\n",
    "            model_.append(model)\n",
    "            precision_.append(\"%.3f\" %prec)\n",
    "\n",
    "            recall_.append(\"%.3f\" %recall)\n",
    "\n",
    "            f1_.append(\"%.3f\" %fscore)\n",
    "\n",
    "            dataset_.append(dataset)\n",
    "\n",
    "        results = list(zip(dataset_ ,bootstrap_sample_correctness, bootstrap_sample_f1,method_,precision_,recall_, f1_))\n",
    "        df_results = pd.DataFrame(results, columns = ['Dataset',  'Bootstrap sample correctness', 'Bootstrap sample f1','Method', 'Precision', 'Recall','F1- Random Forest']) \n",
    "        display(df_results)\n",
    "        \n",
    "        simple_hist, _ = np.histogram(sorted_dataset, bins=100, range=(0.0, 1.0))\n",
    "        plt.plot(np.arange(0.00,1.0,0.01),simple_hist)\n",
    "        for i in range(len(threshold_colors)):\n",
    "            plt.axvline(x=thresholds[i], c= threshold_colors[i])\n",
    "            plt.text(thresholds[i],threshold_text[i],threshold_labels[i],rotation=90)\n",
    "\n",
    "        plt.xlabel('similarity scores')\n",
    "        plt.ylabel('# record pairs')\n",
    "        plt.show()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
